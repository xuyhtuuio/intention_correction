# Intention Correction é¡¹ç›®æ–‡æ¡£

## é¡¹ç›®æ¦‚è¿°

**æ„å›¾çº æ­£æœåŠ¡ï¼ˆIntention Correction Serviceï¼‰** æ˜¯ä¸€ä¸ªåŸºäº RAGï¼ˆRetrieval-Augmented Generationï¼‰æ¶æ„çš„æ™ºèƒ½æ„å›¾è¯†åˆ«ç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºæ•°æ®èµ„äº§å¹³å°çš„ç”¨æˆ·æŸ¥è¯¢æ„å›¾åˆ†æå’Œæ§½ä½æå–ã€‚

### æ ¸å¿ƒåŠŸèƒ½
- **æ„å›¾è¯†åˆ«**ï¼šåˆ†æç”¨æˆ·è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œè¯†åˆ«ç”¨æˆ·æ„å›¾ç±»å‹
- **æ§½ä½æå–**ï¼šä»ç”¨æˆ·æŸ¥è¯¢ä¸­æå–å…³é”®ä¿¡æ¯å‚æ•°
- **RAG å¢å¼º**ï¼šé€šè¿‡å‘é‡æ£€ç´¢å¬å›ç›¸ä¼¼æ ·æœ¬ï¼Œæå‡è¯†åˆ«å‡†ç¡®ç‡
- **å¤šæ„å›¾æ”¯æŒ**ï¼šæ”¯æŒå•æ¬¡æŸ¥è¯¢ä¸­åŒ…å«å¤šä¸ªç‹¬ç«‹æ„å›¾çš„åœºæ™¯

---

## é¡¹ç›®ç»“æ„

```
intention_correction/
â”œâ”€â”€ llm_milvuslite.py      # RAGæœåŠ¡æ ¸å¿ƒé€»è¾‘ï¼ˆä¸»è¦ä¸šåŠ¡æ–‡ä»¶ï¼‰
â”œâ”€â”€ flask_api.py           # Flask REST APIæ¥å£
â”œâ”€â”€ init_milvus.py         # Milvuså‘é‡æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
â”œâ”€â”€ milvuslite_test.py     # Milvusè¿æ¥æµ‹è¯•è„šæœ¬
â”œâ”€â”€ config.ini             # é…ç½®æ–‡ä»¶
â”œâ”€â”€ data.json              # æ„å›¾è¯†åˆ«è®­ç»ƒæ ·æœ¬æ•°æ®ï¼ˆ85æ¡ï¼‰
â”œâ”€â”€ start_flask_api.sh     # Gunicornå¯åŠ¨è„šæœ¬
â”œâ”€â”€ curl.txt               # APIè°ƒç”¨ç¤ºä¾‹
â”œâ”€â”€ milvus.db              # Milvus Liteæ•°æ®åº“æ–‡ä»¶
â”œâ”€â”€ logs/                  # æ—¥å¿—ç›®å½•
â”œâ”€â”€ responses/             # RAGå“åº”ç»“æœå­˜å‚¨ç›®å½•ï¼ˆçº¦560ä¸ªå†å²å“åº”ï¼‰
â”œâ”€â”€ pymilvus2.6.3/         # pymilvusä¾èµ–åŒ…
â”œâ”€â”€ milvuslite2.5.1/       # milvus-liteä¾èµ–åŒ…
â”œâ”€â”€ flask_cors-6.0.1-py3-none-any.whl    # Flask-CORSä¾èµ–
â””â”€â”€ gunicorn-23.0.0-py3-none-any.whl     # Gunicornä¾èµ–
```

---

## æŠ€æœ¯æ¶æ„

### æŠ€æœ¯æ ˆ
| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | è¯´æ˜ |
|------|----------|------|
| Webæ¡†æ¶ | Flask + Flask-CORS | REST APIæœåŠ¡ |
| WSGIæœåŠ¡å™¨ | Gunicorn | ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼Œ4 workers |
| å‘é‡æ•°æ®åº“ | Milvus Lite | è½»é‡çº§å‘é‡å­˜å‚¨ä¸æ£€ç´¢ |
| å¤§è¯­è¨€æ¨¡å‹ | Qwen3-32B | æ„å›¾è¯†åˆ«ä¸ç”Ÿæˆ |
| Embeddingæ¨¡å‹ | bge-m3 | æ–‡æœ¬å‘é‡åŒ–ï¼ˆ1024ç»´ï¼‰ |
| Rerankæ¨¡å‹ | bge-rerank-v2-m3 | å¬å›ç»“æœé‡æ’åº |

### ç³»ç»Ÿæ¶æ„æµç¨‹

```
ç”¨æˆ·æŸ¥è¯¢ â†’ Flask API â†’ RAGæœåŠ¡
                          â†“
                    1. Embeddingç”Ÿæˆï¼ˆbge-m3ï¼‰
                          â†“
                    2. Milvuså‘é‡æ£€ç´¢ï¼ˆtop_k=10ï¼‰
                          â†“
                    3. Reranké‡æ’åºï¼ˆå–top 5ï¼‰
                          â†“
                    4. æ„å»ºRAG Prompt
                          â†“
                    5. LLMæ„å›¾è¯†åˆ«ï¼ˆQwen3-32Bï¼‰
                          â†“
                    è¿”å›JSONç»“æœ
```

---

## é…ç½®è¯´æ˜

### config.ini é…ç½®é¡¹

```ini
[DEFAULT]
# å¤§è¯­è¨€æ¨¡å‹é…ç½®
MODEL_API_URL = http://localhost:8891/v1/chat/completions
MODEL_NAME = Qwen3-32B
TIMEOUT = 300

# Embeddingæ¨¡å‹é…ç½®
EMBEDDING_API_URL = http://localhost:54114/v1/embeddings
EMBEDDING_MODEL_NAME = bge-m3

# Rerankæ¨¡å‹é…ç½®
RERANK_API_URL = http://localhost:54113/v1/rerank
RERANK_MODEL_NAME = bge-rerank-v2-m3

# Milvusé…ç½®
MILVUS_DB_PATH = ./milvus.db
MILVUS_COLLECTION_NAME = intention

# è®­ç»ƒæ•°æ®
INTENTION_EXAMPLE = data.json

# æ—¥å¿—é…ç½®
LOG_DIR = logs
LOG_FILE = app.log

# é»˜è®¤å“åº”
DEFAULT_RESPONSE = å¯¹ä¸èµ·ï¼Œçº æ­£æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚è¯·ç¨åå†è¯•ã€‚
```

---

## æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 1. RAGService ç±» (`llm_milvuslite.py`)

æ ¸å¿ƒæœåŠ¡ç±»ï¼Œæä¾›å®Œæ•´çš„ RAG æŸ¥è¯¢æµç¨‹ã€‚

**ä¸»è¦æ–¹æ³•**ï¼š

| æ–¹æ³• | åŠŸèƒ½ |
|------|------|
| `__init__()` | åˆå§‹åŒ–é…ç½®ã€æ—¥å¿—ã€Milvusè¿æ¥ |
| `_get_embedding(text)` | è°ƒç”¨Embedding APIè·å–æ–‡æœ¬å‘é‡ |
| `_search_similar_documents(query, top_k)` | Milvuså‘é‡ç›¸ä¼¼åº¦æ£€ç´¢ |
| `call_llm(prompt, temperature, enable_thinking)` | è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ |
| `call_rerank(query, documents)` | è°ƒç”¨Rerankæ¨¡å‹é‡æ’åº |
| `rag_query(query, top_k, temperature)` | å®Œæ•´RAGæŸ¥è¯¢æµç¨‹ |
| `_save_response(query, response)` | ä¿å­˜å“åº”ç»“æœåˆ°æ–‡ä»¶ |

**å‘é‡æœç´¢å‚æ•°**ï¼š
- `metric_type`: COSINEï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
- `nprobe`: 10
- `limit`: é»˜è®¤10æ¡

### 2. Flask API (`flask_api.py`)

**API ç«¯ç‚¹**ï¼š

| ç«¯ç‚¹ | æ–¹æ³• | åŠŸèƒ½ |
|------|------|------|
| `/health` | GET | å¥åº·æ£€æŸ¥ |
| `/status` | GET | æœåŠ¡çŠ¶æ€æ£€æŸ¥ï¼ˆåŒ…å«å„ç»„ä»¶çŠ¶æ€ï¼‰ |
| `/rag_query` | POST | å•æ¬¡RAGæŸ¥è¯¢ |
| `/rag_query_batch` | POST | æ‰¹é‡RAGæŸ¥è¯¢ï¼ˆæœ€å¤š10æ¡ï¼‰ |

**è¯·æ±‚ç¤ºä¾‹**ï¼š
```bash
curl -X POST http://localhost:8890/rag_query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "MåŸŸçš„æ‰€æœ‰æ ‡ç­¾èµ„äº§",
    "top_k": 5,
    "temperature": 0.7,
    "chat_template_kwargs": {"enable_thinking": false}
  }'
```

**å“åº”æ ¼å¼**ï¼š
```json
{
  "result": {
    "text": "{\"intent\": \"31\", \"slots\": {\"BusinessDomain\": \"MåŸŸ\", \"AssetType\": \"æ ‡ç­¾\"}, \"query\": \"MåŸŸçš„æ‰€æœ‰æ ‡ç­¾èµ„äº§\"}"
  }
}
```

### 3. Milvusåˆå§‹åŒ– (`init_milvus.py`)

`MilvusIntentionIngestor` ç±»è´Ÿè´£ï¼š
- åˆ›å»º/é‡ç½® Milvus é›†åˆ
- åŠ è½½è®­ç»ƒæ•°æ® (`data.json`)
- æ‰¹é‡ç”Ÿæˆ Embedding å¹¶æ’å…¥å‘é‡æ•°æ®åº“

**é›†åˆSchema**ï¼š
```python
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="input", dtype=DataType.VARCHAR, max_length=65535),  # ç”¨æˆ·æŸ¥è¯¢
    FieldSchema(name="output", dtype=DataType.JSON),                       # æ„å›¾+æ§½ä½
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=1024)  # å‘é‡
]
```

**ç´¢å¼•é…ç½®**ï¼š
- `index_type`: IVF_FLAT
- `metric_type`: COSINE
- `nlist`: 128

---

## æ„å›¾ä½“ç³»

### æ„å›¾ç¼–ç è¡¨

| ç¼–ç  | æ„å›¾åç§° | åŠŸèƒ½æè¿° |
|------|----------|----------|
| 31 | èµ„äº§åŸºç¡€æ£€ç´¢ | åŸºäºåç§°/ID/åŸŸ/ç±»å‹ç­‰æ¡ä»¶æŸ¥æ‰¾èµ„äº§ |
| 32 | èµ„äº§å…ƒæ•°æ®æŸ¥è¯¢ | æŸ¥è¯¢ä¸šåŠ¡å£å¾„/æŠ€æœ¯å£å¾„/è´Ÿè´£äººç­‰å…ƒæ•°æ® |
| 33 | èµ„äº§è´¨é‡ä¸ä»·å€¼æŸ¥è¯¢ | æŸ¥è¯¢ä»·å€¼è¯„åˆ†/æ˜Ÿçº§/è´¨é‡ç¨½æ ¸ |
| 34 | èµ„äº§è¡€ç¼˜å…³ç³»æŸ¥è¯¢ | æŸ¥è¯¢ä¸Šæ¸¸ä¾èµ–/ä¸‹æ¸¸åº”ç”¨/è¡€ç¼˜å›¾ |
| 35 | èµ„äº§ä½¿ç”¨ä¸å·¥å•æŸ¥è¯¢ | æŸ¥è¯¢è®¢é˜…/æ”¶è—/å·¥å•è¿›åº¦/å®¡æ‰¹ |
| 36 | åœºæ™¯ä¸æ ‡ç­¾æ¨è | åŸºäºä¸šåŠ¡ä¸“åŒº/åœºæ™¯æ¨èèµ„äº§ |
| 37 | èµ„äº§å¤åˆå¯¹æ¯”ä¸ç­›é€‰ | å¯¹æ¯”ä¸¤ä¸ªèµ„äº§æˆ–å¤šæ¡ä»¶ç­›é€‰ |
| 38 | å¹³å°è§„åˆ™ä¸å¸®åŠ© | å¹³å°æ“ä½œ/å¸®åŠ©/åè¯è§£é‡Š |
| 39 | åŠ©æ‰‹èƒ½åŠ›ä¸å¸®åŠ© | åŠ©æ‰‹è‡ªèº«èƒ½åŠ›èŒƒå›´ã€åŠŸèƒ½æ¸…å• |
| 40 | OODå…œåº• | ç”¨æˆ·æŸ¥è¯¢ä¸æ„å›¾æ¸…å•ä¸åŒ¹é…æ—¶ |
| 50 | å¤šæ„å›¾å¹¶å‘æŸ¥è¯¢ | ä¸€å¥è¯åŒ…å«å¤šä¸ªç‹¬ç«‹æŸ¥è¯¢æ„å›¾ |

### æ§½ä½å®šä¹‰

| æ§½ä½ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| AssetName | èµ„äº§å®Œæ•´åç§° | `[åœ¨çº¿å…¬å¸]ç»ˆç«¯æ¿€æ´»ä¿¡æ¯(æ—¥)` |
| AssetId | èµ„äº§IDï¼ˆçº¯æ•°å­—ï¼‰ | `1169315655200010241` |
| TableEnglishName | è¡¨è‹±æ–‡å | `ESD_D_CUS_HOME_DEVICE_B` |
| TableChineseName | è¡¨ä¸­æ–‡å | `å®¢æˆ·æ˜Ÿçº§æ•°æ®æœˆå…¨é‡åŠ å·¥è¡¨` |
| MetadataItem | å…ƒæ•°æ®é¡¹ | `ä¸šåŠ¡å£å¾„`/`æŠ€æœ¯å£å¾„`/`è´Ÿè´£äºº` |
| FieldName | å­—æ®µåç§° | `user_id`/`order_id` |
| CoreDataItem | ä¸šåŠ¡æ¦‚å¿µ | `5Gç™»ç½‘`/`ç§»ç½‘ç”¨æˆ·æ˜¯å¦æ´»è·ƒ` |
| BusinessDomain | ä¸šåŠ¡åŸŸ | `MåŸŸ`/`OåŸŸ`/`BåŸŸ` |
| AssetType | èµ„äº§ç±»å‹ | `æ ‡ç­¾`/`æ•°æ®è¡¨`/`æ¨¡å‹èµ„äº§`/`æŒ‡æ ‡` |
| BusinessZone | ä¸šåŠ¡ä¸“åŒº | `å…¬ä¼—æ™ºæ…§è¿è¥`/`ä¸€çº¿èµ‹èƒ½ä¸“åŒº` |
| FilterCondition | ç­›é€‰æ¡ä»¶ | `äº”æ˜Ÿ`/`é«˜ä»·å€¼`/`æœ€è¿‘ä¸€å‘¨æ›´æ–°çš„` |
| LineageDirection | è¡€ç¼˜æ–¹å‘ | `ä¸Šæ¸¸`/`ä¸‹æ¸¸`/`è¡€ç¼˜å›¾` |
| OwnerTenant | å½’å±ç§Ÿæˆ· | `æ€»éƒ¨`/`åˆ†å…¬å¸A` |
| AssetRanking | ç»¼åˆæ’è¡Œ | `æœ€æ–°`/`æœ¬å‘¨ä¸Šæ–°`/`çƒ­é—¨` |
| AssertAdmin | èµ„äº§ç®¡ç†å‘˜ | `å¼ ä¸‰` |
| AssertPublisher | èµ„äº§å‘å¸ƒäºº | `æå››` |
| DataDomain | å½’å±æ•°æ®åŸŸ | `å›ºç½‘è§†å›¾`/`å®¢æˆ·è§†å›¾` |
| DataLayer | å½’å±æ•°æ®å±‚ | `ESD`/`DM`/`SRC`/`DWD` |
| AssetOpenScope | èµ„äº§å¼€æ”¾èŒƒå›´ | `å…¬å…±`/`ç§æœ‰`/`ä¿æŠ¤` |

---

## è¾“å‡ºæ ¼å¼ç¤ºä¾‹

### å•æ„å›¾
```json
{"intent": "31", "slots": {"BusinessDomain": "MåŸŸ", "AssetType": "æ ‡ç­¾"}, "query": "MåŸŸçš„æ‰€æœ‰æ ‡ç­¾èµ„äº§"}
{"intent": "32", "slots": {"AssetName": "å®½å¸¦æè´¨é€Ÿç‡(æœˆ)", "MetadataItem": "ä¸šåŠ¡å£å¾„"}, "query": "å®½å¸¦æè´¨é€Ÿç‡(æœˆ)çš„ä¸šåŠ¡å£å¾„æ˜¯ä»€ä¹ˆï¼Ÿ"}
{"intent": "40", "slots": {}, "query": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}
```

### å¤šæ„å›¾ï¼ˆIntent 50ï¼‰
```json
{
  "intent": "50",
  "slots": [
    {"intent": "31", "slots": {"AssetName": "å®¶åº­åœˆæ¨¡å‹"}},
    {"intent": "32", "slots": {"AssetName": "æ™ºæ…§å®¶åº­å·¥ç¨‹å¸ˆä¿¡æ¯", "MetadataItem": "è´Ÿè´£äºº"}}
  ],
  "query": "æŸ¥è¯¢å®¶åº­åœˆæ¨¡å‹çš„è¯¦æƒ…,ä»¥åŠæ™ºæ…§å®¶åº­å·¥ç¨‹å¸ˆä¿¡æ¯çš„è´Ÿè´£äºº"
}
```

---

## éƒ¨ç½²ä¸è¿è¡Œ

### å¯åŠ¨æœåŠ¡

**å¼€å‘æ¨¡å¼**ï¼š
```bash
python flask_api.py
# æœåŠ¡ç›‘å¬: 0.0.0.0:8890
```

**ç”Ÿäº§æ¨¡å¼ï¼ˆGunicornï¼‰**ï¼š
```bash
./start_flask_api.sh
# æˆ–ç›´æ¥æ‰§è¡Œï¼š
nohup gunicorn --workers 4 --bind 0.0.0.0:8890 --timeout 300 --log-level info flask_api:app > ./logs/gunicorn.log 2>&1 &
```

### åˆå§‹åŒ–å‘é‡æ•°æ®åº“

```bash
python init_milvus.py
```
æ­¤è„šæœ¬ä¼šï¼š
1. è¿æ¥/åˆ›å»º Milvus Lite æ•°æ®åº“
2. åˆ é™¤å¹¶é‡å»º `intention` é›†åˆ
3. åŠ è½½ `data.json` ä¸­çš„è®­ç»ƒæ•°æ®
4. æ‰¹é‡ç”Ÿæˆ Embedding å¹¶æ’å…¥

### æµ‹è¯•è¿æ¥

```bash
python milvuslite_test.py
```

---

## ä¾èµ–è¦æ±‚

### Python åŒ…
```
flask
flask-cors
gunicorn
requests
pymilvus>=2.6.3
milvus-lite>=2.5.1
configparser
numpy
```

### å¤–éƒ¨æœåŠ¡ä¾èµ–
- **LLM API**: `http://localhost:8891/v1/chat/completions` (Qwen3-32B)
- **Embedding API**: `http://localhost:54114/v1/embeddings` (bge-m3)
- **Rerank API**: `http://localhost:54113/v1/rerank` (bge-rerank-v2-m3)

---

## å·²çŸ¥é—®é¢˜ä¸æ³¨æ„äº‹é¡¹

### 1. Rerank æ¨¡å‹åç§°é—®é¢˜
æ—¥å¿—æ˜¾ç¤º `bge-reranker-v2-m3` ä¸å­˜åœ¨ï¼Œé…ç½®æ–‡ä»¶ä¸­çš„åç§°ä¸å®é™…éƒ¨ç½²å¯èƒ½ä¸ä¸€è‡´ã€‚
- é…ç½®å€¼: `bge-rerank-v2-m3`
- é”™è¯¯æç¤º: `The model 'bge-reranker-v2-m3' does not exist`

**è§£å†³æ–¹æ¡ˆ**ï¼šç¡®è®¤ Rerank æœåŠ¡å®é™…æ”¯æŒçš„æ¨¡å‹åç§°ï¼Œæ›´æ–° `config.ini`ã€‚

### 2. å¸ƒå°”å€¼è¯­æ³•é—®é¢˜ï¼ˆå·²ä¿®å¤ï¼‰
å†å²æ—¥å¿—æ˜¾ç¤º `enable_thinking: false` ä½¿ç”¨äº† JavaScript è¯­æ³•ï¼Œåº”ä¸º Python çš„ `False`ã€‚

### 3. æ•°æ®é‡
å½“å‰ Milvus é›†åˆåŒ…å« **85 ä¸ªå®ä½“**ï¼ˆè®­ç»ƒæ ·æœ¬ï¼‰ã€‚

---

## å†å²è®°å½•

### 2025-11-26ï¼ˆç¬¬ä¸‰æ¬¡æ›´æ–°ï¼‰
- **ä¿®å¤ RAG å¬å› bug**ï¼šå‘é‡å¬å›åªè¿”å› `input` å­—æ®µï¼Œç¼ºå°‘ `output`ï¼ˆæ„å›¾+æ§½ä½ï¼‰å¯¼è‡´ few-shot å­¦ä¹ å¤±æ•ˆ
- ä¿®æ”¹ `_search_similar_documents` æ–¹æ³•ï¼š
  - `output_fields=["input"]` â†’ `output_fields=["input", "output"]`
  - è¿”å›ç±»å‹ä» `List[str]` æ”¹ä¸º `List[Dict[str, Any]]`
- ä¿®æ”¹ `rag_query` æ–¹æ³•ï¼š
  - Rerank è°ƒç”¨é€‚é…æ–°çš„æ•°æ®ç»“æ„ï¼ˆæå– input æ–‡æœ¬è¿›è¡Œæ’åºï¼Œé€šè¿‡ index æ˜ å°„å›å®Œæ•´æ–‡æ¡£ï¼‰
  - é‡æ„ä¸Šä¸‹æ–‡æ„å»ºé€»è¾‘ï¼Œç”Ÿæˆ few-shot ç¤ºä¾‹æ ¼å¼ï¼š
    ```
    ç¤ºä¾‹ 1:
    ç”¨æˆ·æŸ¥è¯¢: æŸ¥æ‰¾æ ‡ç­¾èµ„äº§
    æ­£ç¡®è¾“å‡º: {"intent": "31", "slots": {"AssetType": "æ ‡ç­¾"}, "query": "æŸ¥æ‰¾æ ‡ç­¾èµ„äº§"}
    ```
- ä¼˜åŒ– RAG æç¤ºè¯ï¼Œæ˜ç¡®å‘ŠçŸ¥æ¨¡å‹å‚è€ƒç¤ºä¾‹çš„ä½œç”¨

### 2025-11-26ï¼ˆç¬¬äºŒæ¬¡æ›´æ–°ï¼‰
- è®¾è®¡å¹¶å®Œå–„**è‡ªåŠ¨æ ¡å‡†ç³»ç»Ÿæ–¹æ¡ˆ**
- æ ¸å¿ƒæ¨¡å—ï¼šåé¦ˆæ”¶é›†å™¨ã€è¯„ä¼°å¼•æ“ã€è‡ªåŠ¨æ ¡å‡†å™¨ã€æŠ¥å‘Šç”Ÿæˆå™¨
- çœŸå®æ ‡ç­¾è·å–ç­–ç•¥ï¼šä¸šåŠ¡APIåé¦ˆã€ç”¨æˆ·è¡Œä¸ºä¿¡å·ã€LLMäº¤å‰éªŒè¯ã€äººå·¥æŠ½æ ·
- è¯„ä¼°æŒ‡æ ‡ï¼šæ„å›¾å‡†ç¡®ç‡ã€æ§½ä½ç²¾ç¡®ç‡/å¬å›ç‡ã€ä¸šåŠ¡è½¬åŒ–ç‡ã€ç½®ä¿¡åº¦æ ¡å‡†(ECE)
- è‡ªåŠ¨æ ¡å‡†ï¼šé«˜è´¨é‡æ ·æœ¬è‡ªåŠ¨å…¥åº“ã€é—®é¢˜æ ·æœ¬è‡ªåŠ¨ç§»é™¤ã€æ ·æœ¬åº“å¤‡ä»½ä¸å›æ»š

### 2025-11-26ï¼ˆç¬¬ä¸€æ¬¡æ›´æ–°ï¼‰
- Claude å®Œæˆé¡¹ç›®å…¨é¢åˆ†æ
- åˆ›å»º CLAUDE.md é¡¹ç›®æ–‡æ¡£
- é¡¹ç›®æ ¸å¿ƒåŠŸèƒ½ï¼šæ„å›¾è¯†åˆ« + æ§½ä½æå– + RAGå¢å¼º
- æŠ€æœ¯æ ˆï¼šFlask + Milvus Lite + Qwen3-32B + bge-m3
- åˆ†æ Embedding æ¨¡å‹(bge-m3)å’Œ Rerank æ¨¡å‹(bge-rerank-v2-m3)çš„ä½œç”¨

---

## æ–‡ä»¶è¯´æ˜å¿«é€Ÿç´¢å¼•

| æ–‡ä»¶ | è¡Œæ•° | æ ¸å¿ƒåŠŸèƒ½ |
|------|------|----------|
| `llm_milvuslite.py` | ~837è¡Œ | RAGServiceç±»ï¼ŒåŒ…å«å®Œæ•´çš„Promptæ¨¡æ¿ |
| `flask_api.py` | ~392è¡Œ | Flask APIï¼Œå•ä¾‹æ¨¡å¼ç®¡ç†RAGæœåŠ¡ |
| `init_milvus.py` | ~313è¡Œ | MilvusIntentionIngestorç±» |
| `data.json` | ~1217è¡Œ | 85æ¡æ„å›¾è¯†åˆ«è®­ç»ƒæ ·æœ¬ |
| `config.ini` | 15è¡Œ | æ‰€æœ‰å¤–éƒ¨æœåŠ¡é…ç½® |

---

## è‡ªåŠ¨æ ¡å‡†ç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆ

### ä¸€ã€ç³»ç»Ÿæ¦‚è¿°

**æ„å›¾è¯†åˆ«è‡ªåŠ¨æ ¡å‡†ç³»ç»Ÿï¼ˆIntent Calibration Systemï¼‰** æ˜¯ä¸€ä¸ªç”¨äºåŠ¨æ€ç›‘æµ‹æ„å›¾è¯†åˆ«å‡†ç¡®åº¦ã€è‡ªåŠ¨ä¼˜åŒ–æ ·æœ¬åº“ã€å¹¶ç”Ÿæˆè¯„ä¼°æŠ¥å‘Šçš„é—­ç¯ç³»ç»Ÿã€‚

#### è®¾è®¡ç›®æ ‡
- **åŠ¨æ€è§‚æµ‹**ï¼šå®æ—¶æˆ–å®šæœŸè¯„ä¼°æ„å›¾è¯†åˆ«çš„å‡†ç¡®åº¦
- **è‡ªåŠ¨æ ¡å‡†**ï¼šæ ¹æ®è¯„ä¼°ç»“æœè‡ªåŠ¨è°ƒæ•´è®­ç»ƒæ ·æœ¬åº“
- **æŠ¥å‘Šè¾“å‡º**ï¼šç”Ÿæˆå¤šç»´åº¦çš„å‡†ç¡®åº¦è¯„ä¼°æŠ¥å‘Š

#### æ ¸å¿ƒè®¾è®¡åŸåˆ™

| åŸåˆ™ | è¯´æ˜ |
|------|------|
| **æ— éœ€äººå·¥æ ‡æ³¨** | é€šè¿‡ä¸šåŠ¡é—­ç¯å’Œç”¨æˆ·è¡Œä¸ºè‡ªåŠ¨è·å–çœŸå®æ ‡ç­¾ |
| **éä¾µå…¥å¼** | å¼‚æ­¥å¤„ç†ï¼Œä¸å½±å“ä¸»æœåŠ¡æ€§èƒ½ |
| **æ¸è¿›å¼æ ¡å‡†** | å°æ­¥è¿­ä»£ï¼Œé¿å…å¤§å¹…æ³¢åŠ¨ |
| **å¯å›æ»š** | æ¯æ¬¡æ ¡å‡†ä¿ç•™å¿«ç…§ï¼Œæ”¯æŒå›é€€ |
| **å¤šç»´åº¦è¯„ä¼°** | æ„å›¾å‡†ç¡®ç‡ + æ§½ä½ç²¾ç¡®ç‡ + ä¸šåŠ¡è½¬åŒ–ç‡ |

---

### äºŒã€ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æ„å›¾è¯†åˆ«è‡ªåŠ¨æ ¡å‡†ç³»ç»Ÿ (Intent Calibration System)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚   æ•°æ®é‡‡é›†å±‚   â”‚â”€â”€â”€â–¶â”‚   è¯„ä¼°å¼•æ“å±‚   â”‚â”€â”€â”€â–¶â”‚   æ ¡å‡†æ‰§è¡Œå±‚   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚         â”‚                   â”‚                   â”‚                          â”‚
â”‚         â–¼                   â–¼                   â–¼                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  åé¦ˆå­˜å‚¨åº“   â”‚    â”‚   æŒ‡æ ‡è®¡ç®—å™¨   â”‚    â”‚  æ ·æœ¬ç®¡ç†å™¨   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚         â”‚                   â”‚                   â”‚                          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                             â”‚                                              â”‚
â”‚                             â–¼                                              â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚                    â”‚   æŠ¥å‘Šç”Ÿæˆå™¨   â”‚                                        â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ä¸‰ã€çœŸå®æ ‡ç­¾è·å–ç­–ç•¥ï¼ˆæ ¸å¿ƒéš¾ç‚¹ï¼‰

åœ¨æ²¡æœ‰äººå·¥æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œç³»ç»Ÿé€šè¿‡ä»¥ä¸‹å››ç§æ¥æºè‡ªåŠ¨è·å–"çœŸå®æ ‡ç­¾"ï¼š

#### 1. ä¸šåŠ¡æ‰§è¡Œåé¦ˆï¼ˆæœ€å¯é ï¼‰
```
ç”¨æˆ·æŸ¥è¯¢ â†’ æ„å›¾è¯†åˆ« â†’ è°ƒç”¨ä¸‹æ¸¸API â†’ APIæ‰§è¡ŒæˆåŠŸ/å¤±è´¥
                                        â†“
                                 æˆåŠŸ = æ„å›¾æ­£ç¡®
                                 å¤±è´¥ = å¯èƒ½æ„å›¾é”™è¯¯
```

#### 2. ç”¨æˆ·è¡Œä¸ºä¿¡å·ï¼ˆéšå¼åé¦ˆï¼‰
| è¡Œä¸º | è§£è¯» |
|------|------|
| ç”¨æˆ·é‡æ–°æé—®(rephrase) | ä¸Šæ¬¡è¯†åˆ«å¯èƒ½æœ‰è¯¯ |
| ç”¨æˆ·ç‚¹å‡»"æ¢ä¸€ä¸ªå›ç­”" | å½“å‰ç»“æœä¸æ»¡æ„ |
| ç”¨æˆ·å®Œæˆä¸šåŠ¡æµç¨‹ | è¯†åˆ«æ­£ç¡® |
| ä¼šè¯è½®æ¬¡è¿‡å¤š | ä½“éªŒä¸ä½³ |

#### 3. LLMè‡ªæ ¡éªŒï¼ˆCross-Validationï¼‰
```
åŒä¸€æŸ¥è¯¢ç”¨ä¸åŒæ¸©åº¦/Promptå¤šæ¬¡æ¨ç†
ç»“æœä¸€è‡´æ€§é«˜ â†’ ç½®ä¿¡åº¦é«˜
ç»“æœåˆ†æ­§å¤§ â†’ æ ‡è®°ä¸º"å¾…å®¡æ ¸"
```

#### 4. äººå·¥æŠ½æ ·å®¡æ ¸ï¼ˆå®šæœŸï¼‰
æ¯æ—¥/æ¯å‘¨æŠ½å–ä½ç½®ä¿¡åº¦æ ·æœ¬è¿›è¡Œäººå·¥æ ¡éªŒï¼Œä½œä¸ºè¯„ä¼°åŸºå‡†çš„"é‡‘æ ‡å‡†"ã€‚

---

### å››ã€æ•°æ®æ¨¡å‹è®¾è®¡

#### 4.1 é¢„æµ‹è®°å½•æ¨¡å‹

```python
from dataclasses import dataclass, field
from typing import Optional, Dict, List, Any
from enum import Enum
from datetime import datetime
import uuid


class FeedbackSource(Enum):
    """åé¦ˆæ¥æº"""
    BUSINESS_API = "business_api"      # ä¸šåŠ¡APIæ‰§è¡Œç»“æœ
    USER_BEHAVIOR = "user_behavior"    # ç”¨æˆ·è¡Œä¸ºä¿¡å·
    LLM_CROSS_CHECK = "llm_cross"      # LLMäº¤å‰éªŒè¯
    HUMAN_REVIEW = "human_review"      # äººå·¥å®¡æ ¸


class FeedbackSignal(Enum):
    """åé¦ˆä¿¡å·ç±»å‹"""
    POSITIVE = "positive"              # æ­£å‘åé¦ˆï¼ˆè¯†åˆ«æ­£ç¡®ï¼‰
    NEGATIVE = "negative"              # è´Ÿå‘åé¦ˆï¼ˆè¯†åˆ«é”™è¯¯ï¼‰
    UNCERTAIN = "uncertain"            # ä¸ç¡®å®š


@dataclass
class PredictionRecord:
    """å•æ¬¡é¢„æµ‹è®°å½•"""
    record_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    timestamp: datetime = field(default_factory=datetime.now)

    # è¾“å…¥
    query: str = ""

    # é¢„æµ‹è¾“å‡º
    predicted_intent: str = ""
    predicted_slots: Dict[str, Any] = field(default_factory=dict)
    confidence_score: float = 0.0      # æ¨¡å‹ç½®ä¿¡åº¦

    # RAGä¸Šä¸‹æ–‡
    retrieved_docs: List[str] = field(default_factory=list)
    rerank_scores: List[float] = field(default_factory=list)

    # çœŸå®æ ‡ç­¾ï¼ˆåç»­å¡«å……ï¼‰
    actual_intent: Optional[str] = None
    actual_slots: Optional[Dict[str, Any]] = None

    # åé¦ˆä¿¡æ¯
    feedback_source: Optional[FeedbackSource] = None
    feedback_signal: Optional[FeedbackSignal] = None
    feedback_detail: Optional[str] = None
    feedback_timestamp: Optional[datetime] = None

    # ä¸šåŠ¡ç»“æœ
    downstream_api_called: Optional[str] = None
    downstream_api_success: Optional[bool] = None
    business_conversion: Optional[bool] = None  # æ˜¯å¦å®Œæˆä¸šåŠ¡ç›®æ ‡
```

#### 4.2 è¯„ä¼°æŒ‡æ ‡æ¨¡å‹

```python
@dataclass
class EvaluationMetrics:
    """è¯„ä¼°æŒ‡æ ‡"""
    eval_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    eval_timestamp: datetime = field(default_factory=datetime.now)
    eval_period_start: datetime = None
    eval_period_end: datetime = None
    sample_count: int = 0

    # æ„å›¾çº§åˆ«æŒ‡æ ‡
    intent_accuracy: float = 0.0                    # æ•´ä½“å‡†ç¡®ç‡
    intent_precision: Dict[str, float] = field(default_factory=dict)  # å„æ„å›¾ç²¾ç¡®ç‡
    intent_recall: Dict[str, float] = field(default_factory=dict)     # å„æ„å›¾å¬å›ç‡
    intent_f1: Dict[str, float] = field(default_factory=dict)         # å„æ„å›¾F1
    intent_confusion_matrix: Dict[str, Dict[str, int]] = field(default_factory=dict)

    # æ§½ä½çº§åˆ«æŒ‡æ ‡
    slot_precision: float = 0.0                     # æ§½ä½ç²¾ç¡®ç‡
    slot_recall: float = 0.0                        # æ§½ä½å¬å›ç‡
    slot_f1: float = 0.0
    slot_exact_match: float = 0.0                   # æ§½ä½å®Œå…¨åŒ¹é…ç‡

    # ä¸šåŠ¡çº§åˆ«æŒ‡æ ‡
    business_success_rate: float = 0.0              # ä¸šåŠ¡è½¬åŒ–ç‡
    avg_session_turns: float = 0.0                  # å¹³å‡ä¼šè¯è½®æ¬¡
    rephrase_rate: float = 0.0                      # ç”¨æˆ·é‡è¿°ç‡

    # ç½®ä¿¡åº¦æ ¡å‡†æŒ‡æ ‡
    calibration_error: float = 0.0                  # ECE (Expected Calibration Error)
    confidence_histogram: Dict[str, int] = field(default_factory=dict)

    # å¼‚å¸¸æ£€æµ‹
    low_confidence_count: int = 0                   # ä½ç½®ä¿¡åº¦æ ·æœ¬æ•°
    ood_detection_rate: float = 0.0                 # OODæ£€æµ‹ç‡
```

---

### äº”ã€æ ¸å¿ƒæ¨¡å—å®ç°

#### 5.1 åé¦ˆæ”¶é›†å™¨ (FeedbackCollector)

```python
import json
import logging
from typing import Optional, Dict
from datetime import datetime
import threading
import queue


class FeedbackCollector:
    """
    åé¦ˆæ”¶é›†å™¨ - å¼‚æ­¥æ”¶é›†å„ç±»åé¦ˆä¿¡å·

    è®¾è®¡åŸåˆ™ï¼š
    1. éé˜»å¡ï¼šä¸å½±å“ä¸»æœåŠ¡å“åº”
    2. æ‰¹é‡å†™å…¥ï¼šå‡å°‘IOå‹åŠ›
    3. å¤šæºèåˆï¼šæ•´åˆä¸åŒæ¥æºçš„åé¦ˆ
    """

    def __init__(self, storage_path: str = "./calibration_data"):
        self.storage_path = storage_path
        self.logger = logging.getLogger(__name__)

        # å¼‚æ­¥é˜Ÿåˆ—
        self._feedback_queue = queue.Queue(maxsize=10000)
        self._prediction_cache: Dict[str, PredictionRecord] = {}
        self._cache_lock = threading.Lock()

        # å¯åŠ¨åå°å†™å…¥çº¿ç¨‹
        self._start_background_writer()

    def record_prediction(self, record: PredictionRecord) -> str:
        """
        è®°å½•ä¸€æ¬¡é¢„æµ‹ï¼ˆä¸»æœåŠ¡è°ƒç”¨ï¼‰

        Returns:
            record_id: ç”¨äºåç»­å…³è”åé¦ˆ
        """
        with self._cache_lock:
            self._prediction_cache[record.record_id] = record

        # è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆ24å°æ—¶åå¦‚æœæ²¡æœ‰åé¦ˆåˆ™æŒä¹…åŒ–ï¼‰
        threading.Timer(
            86400,
            self._expire_record,
            args=[record.record_id]
        ).start()

        return record.record_id

    def collect_business_feedback(
        self,
        record_id: str,
        api_name: str,
        api_success: bool,
        error_msg: Optional[str] = None
    ):
        """
        æ”¶é›†ä¸šåŠ¡APIæ‰§è¡Œåé¦ˆ

        è¿™æ˜¯æœ€å¯é çš„åé¦ˆæ¥æºï¼š
        - APIæ‰§è¡ŒæˆåŠŸ â†’ æ„å›¾è¯†åˆ«å¤§æ¦‚ç‡æ­£ç¡®
        - APIæ‰§è¡Œå¤±è´¥(å‚æ•°é”™è¯¯) â†’ æ§½ä½æå–å¯èƒ½æœ‰è¯¯
        - APIæ‰§è¡Œå¤±è´¥(æ— ç»“æœ) â†’ æ„å›¾å¯èƒ½é”™è¯¯
        """
        with self._cache_lock:
            if record_id not in self._prediction_cache:
                self.logger.warning(f"Record {record_id} not found")
                return

            record = self._prediction_cache[record_id]
            record.downstream_api_called = api_name
            record.downstream_api_success = api_success
            record.feedback_source = FeedbackSource.BUSINESS_API
            record.feedback_timestamp = datetime.now()

            # æ¨æ–­åé¦ˆä¿¡å·
            if api_success:
                record.feedback_signal = FeedbackSignal.POSITIVE
            else:
                if error_msg and "å‚æ•°" in error_msg:
                    record.feedback_signal = FeedbackSignal.NEGATIVE
                    record.feedback_detail = f"æ§½ä½æå–å¯èƒ½æœ‰è¯¯: {error_msg}"
                else:
                    record.feedback_signal = FeedbackSignal.UNCERTAIN
                    record.feedback_detail = error_msg

        self._feedback_queue.put(record_id)

    def collect_user_behavior(
        self,
        record_id: str,
        behavior_type: str,  # "rephrase", "click_retry", "complete_flow", "abandon"
        detail: Optional[Dict] = None
    ):
        """
        æ”¶é›†ç”¨æˆ·è¡Œä¸ºä¿¡å·

        è¡Œä¸ºä¿¡å·è§£è¯»ï¼š
        - rephrase: ç”¨æˆ·æ¢äº†ä¸€ç§è¯´æ³•é‡æ–°æé—® â†’ ä¸Šæ¬¡è¯†åˆ«å¯èƒ½ä¸å‡†
        - click_retry: ç”¨æˆ·ç‚¹å‡»é‡è¯•/æ¢ä¸€ä¸ª â†’ å½“å‰ç»“æœä¸æ»¡æ„
        - complete_flow: ç”¨æˆ·å®Œæˆäº†æ•´ä¸ªä¸šåŠ¡æµç¨‹ â†’ è¯†åˆ«æ­£ç¡®
        - abandon: ç”¨æˆ·æ”¾å¼ƒ/ç¦»å¼€ â†’ ä½“éªŒä¸ä½³
        """
        with self._cache_lock:
            if record_id not in self._prediction_cache:
                return

            record = self._prediction_cache[record_id]
            record.feedback_source = FeedbackSource.USER_BEHAVIOR
            record.feedback_timestamp = datetime.now()

            if behavior_type == "complete_flow":
                record.feedback_signal = FeedbackSignal.POSITIVE
                record.business_conversion = True
            elif behavior_type in ["rephrase", "click_retry"]:
                record.feedback_signal = FeedbackSignal.NEGATIVE
                record.feedback_detail = f"ç”¨æˆ·è¡Œä¸º: {behavior_type}"
            elif behavior_type == "abandon":
                record.feedback_signal = FeedbackSignal.UNCERTAIN
                record.feedback_detail = "ç”¨æˆ·æ”¾å¼ƒ"

        self._feedback_queue.put(record_id)

    def collect_llm_cross_check(
        self,
        record_id: str,
        alternative_results: List[Dict],
        consistency_score: float
    ):
        """
        æ”¶é›†LLMäº¤å‰éªŒè¯ç»“æœ

        åŒä¸€æŸ¥è¯¢ç”¨ä¸åŒå‚æ•°å¤šæ¬¡æ¨ç†ï¼Œæ£€æŸ¥ç»“æœä¸€è‡´æ€§
        """
        with self._cache_lock:
            if record_id not in self._prediction_cache:
                return

            record = self._prediction_cache[record_id]
            record.feedback_source = FeedbackSource.LLM_CROSS_CHECK
            record.confidence_score = consistency_score

            if consistency_score >= 0.9:
                record.feedback_signal = FeedbackSignal.POSITIVE
            elif consistency_score >= 0.7:
                record.feedback_signal = FeedbackSignal.UNCERTAIN
            else:
                record.feedback_signal = FeedbackSignal.NEGATIVE
                record.feedback_detail = f"LLMç»“æœä¸ä¸€è‡´: {alternative_results}"

        self._feedback_queue.put(record_id)

    def _start_background_writer(self):
        """å¯åŠ¨åå°å†™å…¥çº¿ç¨‹"""
        def writer_loop():
            batch = []
            while True:
                try:
                    record_id = self._feedback_queue.get(timeout=60)
                    with self._cache_lock:
                        if record_id in self._prediction_cache:
                            batch.append(self._prediction_cache.pop(record_id))

                    if len(batch) >= 100:
                        self._persist_batch(batch)
                        batch = []
                except queue.Empty:
                    if batch:
                        self._persist_batch(batch)
                        batch = []

        thread = threading.Thread(target=writer_loop, daemon=True)
        thread.start()

    def _persist_batch(self, records: List[PredictionRecord]):
        """æ‰¹é‡æŒä¹…åŒ–åˆ°å­˜å‚¨"""
        # å®ç°å­˜å‚¨é€»è¾‘ï¼ˆæ–‡ä»¶/æ•°æ®åº“ï¼‰
        pass

    def _expire_record(self, record_id: str):
        """è¿‡æœŸå¤„ç†ï¼šæ²¡æœ‰æ”¶åˆ°åé¦ˆçš„è®°å½•"""
        with self._cache_lock:
            if record_id in self._prediction_cache:
                record = self._prediction_cache.pop(record_id)
                record.feedback_signal = FeedbackSignal.UNCERTAIN
                record.feedback_detail = "æœªæ”¶åˆ°åé¦ˆï¼Œå·²è¿‡æœŸ"
                self._feedback_queue.put_nowait(record_id)
```

#### 5.2 è¯„ä¼°å¼•æ“ (EvaluationEngine)

```python
import numpy as np
from collections import defaultdict
from typing import List, Tuple


class EvaluationEngine:
    """
    è¯„ä¼°å¼•æ“ - è®¡ç®—å„ç»´åº¦æŒ‡æ ‡

    è¯„ä¼°ç»´åº¦ï¼š
    1. æ„å›¾åˆ†ç±»å‡†ç¡®ç‡
    2. æ§½ä½æå–å‡†ç¡®ç‡
    3. ä¸šåŠ¡è½¬åŒ–æŒ‡æ ‡
    4. ç½®ä¿¡åº¦æ ¡å‡†
    """

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.intent_list = ["31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "50"]

    def evaluate(
        self,
        records: List[PredictionRecord],
        period_start: datetime = None,
        period_end: datetime = None
    ) -> EvaluationMetrics:
        """æ‰§è¡Œå®Œæ•´è¯„ä¼°"""
        metrics = EvaluationMetrics(
            eval_period_start=period_start,
            eval_period_end=period_end,
            sample_count=len(records)
        )

        valid_records = [r for r in records if r.actual_intent is not None]
        feedback_records = [r for r in records if r.feedback_signal is not None]

        if not valid_records and not feedback_records:
            self.logger.warning("æ²¡æœ‰æœ‰æ•ˆè¯„ä¼°æ ·æœ¬")
            return metrics

        # 1. æ„å›¾çº§åˆ«è¯„ä¼°
        if valid_records:
            self._evaluate_intent(valid_records, metrics)
            self._evaluate_slots(valid_records, metrics)

        # 2. åŸºäºåé¦ˆçš„è¯„ä¼°
        if feedback_records:
            self._evaluate_from_feedback(feedback_records, metrics)

        # 3. ä¸šåŠ¡æŒ‡æ ‡è¯„ä¼°
        self._evaluate_business(records, metrics)

        # 4. ç½®ä¿¡åº¦æ ¡å‡†è¯„ä¼°
        self._evaluate_calibration(records, metrics)

        return metrics

    def _evaluate_intent(self, records: List[PredictionRecord], metrics: EvaluationMetrics):
        """æ„å›¾åˆ†ç±»è¯„ä¼°"""
        y_true = [r.actual_intent for r in records]
        y_pred = [r.predicted_intent for r in records]

        # æ•´ä½“å‡†ç¡®ç‡
        correct = sum(1 for t, p in zip(y_true, y_pred) if t == p)
        metrics.intent_accuracy = correct / len(records)

        # æ··æ·†çŸ©é˜µ
        confusion = defaultdict(lambda: defaultdict(int))
        for t, p in zip(y_true, y_pred):
            confusion[t][p] += 1
        metrics.intent_confusion_matrix = dict(confusion)

        # å„æ„å›¾çš„ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1
        for intent in self.intent_list:
            tp = confusion[intent][intent]
            fp = sum(confusion[other][intent] for other in self.intent_list if other != intent)
            fn = sum(confusion[intent][other] for other in self.intent_list if other != intent)

            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

            metrics.intent_precision[intent] = precision
            metrics.intent_recall[intent] = recall
            metrics.intent_f1[intent] = f1

    def _evaluate_slots(self, records: List[PredictionRecord], metrics: EvaluationMetrics):
        """æ§½ä½æå–è¯„ä¼°"""
        total_tp, total_fp, total_fn = 0, 0, 0
        exact_match_count = 0

        for record in records:
            if record.actual_slots is None:
                continue

            pred_slots = set(record.predicted_slots.items())
            actual_slots = set(record.actual_slots.items())

            tp = len(pred_slots & actual_slots)
            fp = len(pred_slots - actual_slots)
            fn = len(actual_slots - pred_slots)

            total_tp += tp
            total_fp += fp
            total_fn += fn

            if pred_slots == actual_slots:
                exact_match_count += 1

        metrics.slot_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0
        metrics.slot_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0
        metrics.slot_f1 = (2 * metrics.slot_precision * metrics.slot_recall /
                          (metrics.slot_precision + metrics.slot_recall)
                          if (metrics.slot_precision + metrics.slot_recall) > 0 else 0)
        metrics.slot_exact_match = exact_match_count / len(records) if records else 0

    def _evaluate_from_feedback(self, records: List[PredictionRecord], metrics: EvaluationMetrics):
        """åŸºäºåé¦ˆä¿¡å·çš„è¯„ä¼°ï¼ˆæ— çœŸå®æ ‡ç­¾æ—¶çš„æ›¿ä»£æ–¹æ¡ˆï¼‰"""
        positive_count = sum(1 for r in records if r.feedback_signal == FeedbackSignal.POSITIVE)
        negative_count = sum(1 for r in records if r.feedback_signal == FeedbackSignal.NEGATIVE)

        total = positive_count + negative_count
        if total > 0:
            feedback_accuracy = positive_count / total
            if metrics.intent_accuracy == 0:
                metrics.intent_accuracy = feedback_accuracy

    def _evaluate_business(self, records: List[PredictionRecord], metrics: EvaluationMetrics):
        """ä¸šåŠ¡æŒ‡æ ‡è¯„ä¼°"""
        conversion_records = [r for r in records if r.business_conversion is not None]
        if conversion_records:
            success_count = sum(1 for r in conversion_records if r.business_conversion)
            metrics.business_success_rate = success_count / len(conversion_records)

        rephrase_records = [r for r in records
                          if r.feedback_source == FeedbackSource.USER_BEHAVIOR
                          and r.feedback_detail and "rephrase" in r.feedback_detail]
        if records:
            metrics.rephrase_rate = len(rephrase_records) / len(records)

    def _evaluate_calibration(self, records: List[PredictionRecord], metrics: EvaluationMetrics):
        """
        ç½®ä¿¡åº¦æ ¡å‡†è¯„ä¼°

        ECE (Expected Calibration Error): ç½®ä¿¡åº¦ä¸å®é™…å‡†ç¡®ç‡çš„å·®è·
        ç†æƒ³æƒ…å†µï¼šç½®ä¿¡åº¦90%çš„æ ·æœ¬ï¼Œå‡†ç¡®ç‡åº”è¯¥æ¥è¿‘90%
        """
        bins = defaultdict(list)
        for record in records:
            if record.confidence_score > 0:
                bin_idx = int(record.confidence_score * 10)
                is_correct = (record.feedback_signal == FeedbackSignal.POSITIVE or
                             (record.actual_intent and record.actual_intent == record.predicted_intent))
                bins[bin_idx].append((record.confidence_score, is_correct))

        total_samples = sum(len(b) for b in bins.values())
        ece = 0
        for bin_idx, samples in bins.items():
            if samples:
                avg_confidence = np.mean([s[0] for s in samples])
                avg_accuracy = np.mean([s[1] for s in samples])
                ece += len(samples) / total_samples * abs(avg_confidence - avg_accuracy)

        metrics.calibration_error = ece
        metrics.low_confidence_count = sum(1 for r in records if r.confidence_score < 0.7)
```

#### 5.3 è‡ªåŠ¨æ ¡å‡†å™¨ (AutoCalibrator)

```python
import shutil
from pathlib import Path


class AutoCalibrator:
    """
    è‡ªåŠ¨æ ¡å‡†å™¨ - æ ¹æ®è¯„ä¼°ç»“æœè°ƒæ•´ç³»ç»Ÿ

    æ ¡å‡†ç­–ç•¥ï¼š
    1. æ ·æœ¬åº“åŠ¨æ€è°ƒæ•´ï¼šæ·»åŠ é«˜è´¨é‡æ ·æœ¬ã€ç§»é™¤å™ªå£°æ ·æœ¬
    2. é˜ˆå€¼è°ƒæ•´ï¼šè°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼
    3. è§¦å‘å‘Šè­¦ï¼šå‡†ç¡®ç‡ä¸‹é™æ—¶å‘Šè­¦
    """

    def __init__(
        self,
        data_json_path: str = "data.json",
        backup_dir: str = "./calibration_backups",
        min_accuracy_threshold: float = 0.85,
        max_sample_size: int = 500
    ):
        self.data_json_path = data_json_path
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(exist_ok=True)
        self.min_accuracy_threshold = min_accuracy_threshold
        self.max_sample_size = max_sample_size
        self.logger = logging.getLogger(__name__)

    def calibrate(
        self,
        metrics: EvaluationMetrics,
        feedback_records: List[PredictionRecord]
    ) -> Dict[str, Any]:
        """æ‰§è¡Œæ ¡å‡†ï¼Œè¿”å›æ ¡å‡†æŠ¥å‘Š"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "actions_taken": [],
            "alerts": [],
            "recommendations": []
        }

        # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦å‘Šè­¦
        self._check_alerts(metrics, report)

        # 2. è¯†åˆ«é«˜è´¨é‡æ–°æ ·æœ¬
        new_samples = self._identify_quality_samples(feedback_records)

        # 3. è¯†åˆ«é—®é¢˜æ ·æœ¬
        problem_samples = self._identify_problem_samples(feedback_records, metrics)

        # 4. æ‰§è¡Œæ ·æœ¬åº“æ›´æ–°
        if new_samples or problem_samples:
            self._update_sample_library(new_samples, problem_samples, report)

        # 5. ç”Ÿæˆä¼˜åŒ–å»ºè®®
        self._generate_recommendations(metrics, report)

        return report

    def _check_alerts(self, metrics: EvaluationMetrics, report: Dict):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦å‘Šè­¦"""
        if metrics.intent_accuracy < self.min_accuracy_threshold:
            report["alerts"].append({
                "level": "critical",
                "type": "accuracy_drop",
                "message": f"æ„å›¾å‡†ç¡®ç‡é™è‡³ {metrics.intent_accuracy:.2%}ï¼Œä½äºé˜ˆå€¼ {self.min_accuracy_threshold:.2%}",
                "metric_value": metrics.intent_accuracy
            })

        for intent, f1 in metrics.intent_f1.items():
            if f1 < 0.7:
                report["alerts"].append({
                    "level": "warning",
                    "type": "intent_performance",
                    "message": f"æ„å›¾ {intent} çš„F1åˆ†æ•°è¾ƒä½: {f1:.2%}",
                    "intent": intent,
                    "metric_value": f1
                })

        if metrics.calibration_error > 0.15:
            report["alerts"].append({
                "level": "warning",
                "type": "calibration",
                "message": f"ç½®ä¿¡åº¦æ ¡å‡†è¯¯å·®è¿‡å¤§: {metrics.calibration_error:.2%}",
                "metric_value": metrics.calibration_error
            })

    def _identify_quality_samples(self, records: List[PredictionRecord]) -> List[Dict]:
        """
        è¯†åˆ«é«˜è´¨é‡æ ·æœ¬ï¼ˆå¯åŠ å…¥è®­ç»ƒé›†ï¼‰

        æ ‡å‡†ï¼š
        1. æœ‰æ­£å‘åé¦ˆ
        2. ç½®ä¿¡åº¦é«˜
        3. ä¸šåŠ¡æ‰§è¡ŒæˆåŠŸ
        """
        quality_samples = []

        for record in records:
            score = 0

            if record.feedback_signal == FeedbackSignal.POSITIVE:
                score += 2
            if record.downstream_api_success:
                score += 2
            if record.confidence_score >= 0.9:
                score += 1
            if record.feedback_source == FeedbackSource.BUSINESS_API:
                score += 1

            if score >= 4:
                quality_samples.append({
                    "input": record.query,
                    "output": {
                        "intent": record.predicted_intent,
                        "slots": record.predicted_slots,
                        "query": record.query
                    },
                    "quality_score": score,
                    "source": "auto_calibration"
                })

        return quality_samples

    def _identify_problem_samples(
        self,
        records: List[PredictionRecord],
        metrics: EvaluationMetrics
    ) -> List[str]:
        """è¯†åˆ«é—®é¢˜æ ·æœ¬ï¼ˆéœ€è¦ä»è®­ç»ƒé›†ç§»é™¤æˆ–ä¿®æ­£ï¼‰"""
        problem_queries = []

        for record in records:
            if record.feedback_signal == FeedbackSignal.NEGATIVE:
                problem_queries.append(record.query)

        return problem_queries

    def _update_sample_library(
        self,
        new_samples: List[Dict],
        problem_queries: List[str],
        report: Dict
    ):
        """æ›´æ–°æ ·æœ¬åº“"""
        # 1. å¤‡ä»½å½“å‰æ ·æœ¬åº“
        backup_path = self.backup_dir / f"data_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        shutil.copy(self.data_json_path, backup_path)
        report["actions_taken"].append(f"å·²å¤‡ä»½æ ·æœ¬åº“åˆ° {backup_path}")

        # 2. åŠ è½½å½“å‰æ ·æœ¬
        with open(self.data_json_path, 'r', encoding='utf-8') as f:
            current_samples = json.load(f)

        original_count = len(current_samples)

        # 3. ç§»é™¤é—®é¢˜æ ·æœ¬
        if problem_queries:
            current_samples = [
                s for s in current_samples
                if s.get("input") not in problem_queries
            ]
            removed_count = original_count - len(current_samples)
            if removed_count > 0:
                report["actions_taken"].append(f"ç§»é™¤ {removed_count} ä¸ªé—®é¢˜æ ·æœ¬")

        # 4. æ·»åŠ æ–°æ ·æœ¬ï¼ˆå»é‡ï¼‰
        existing_queries = {s.get("input") for s in current_samples}
        added_count = 0
        for sample in new_samples:
            if sample["input"] not in existing_queries:
                current_samples.append({
                    "input": sample["input"],
                    "output": sample["output"]
                })
                existing_queries.add(sample["input"])
                added_count += 1

                if len(current_samples) >= self.max_sample_size:
                    break

        if added_count > 0:
            report["actions_taken"].append(f"æ·»åŠ  {added_count} ä¸ªé«˜è´¨é‡æ ·æœ¬")

        # 5. ä¿å­˜æ›´æ–°åçš„æ ·æœ¬åº“
        with open(self.data_json_path, 'w', encoding='utf-8') as f:
            json.dump(current_samples, f, ensure_ascii=False, indent=2)

        report["actions_taken"].append(f"æ ·æœ¬åº“å·²æ›´æ–°: {original_count} â†’ {len(current_samples)}")

    def _generate_recommendations(self, metrics: EvaluationMetrics, report: Dict):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        for intent, f1 in metrics.intent_f1.items():
            if f1 < 0.8:
                precision = metrics.intent_precision.get(intent, 0)
                recall = metrics.intent_recall.get(intent, 0)

                if precision < recall:
                    report["recommendations"].append({
                        "intent": intent,
                        "issue": "ç²¾ç¡®ç‡ä½",
                        "suggestion": f"æ„å›¾ {intent} å®¹æ˜“è¢«è¯¯åˆ¤ï¼Œå»ºè®®æ·»åŠ æ›´å¤šè¾¹ç•Œæ ·æœ¬æˆ–è°ƒæ•´Promptä¸­çš„åŒºåˆ†è§„åˆ™"
                    })
                else:
                    report["recommendations"].append({
                        "intent": intent,
                        "issue": "å¬å›ç‡ä½",
                        "suggestion": f"æ„å›¾ {intent} å®¹æ˜“æ¼åˆ¤ï¼Œå»ºè®®æ·»åŠ æ›´å¤šè¯¥æ„å›¾çš„å¤šæ ·åŒ–è¡¨è¿°æ ·æœ¬"
                    })

        if metrics.ood_detection_rate < 0.9:
            report["recommendations"].append({
                "intent": "40",
                "issue": "OODæ£€æµ‹ç‡ä½",
                "suggestion": "å»ºè®®æ·»åŠ æ›´å¤šOODæ ·æœ¬ï¼Œæˆ–åœ¨Promptä¸­å¼ºè°ƒOODåˆ¤æ–­è§„åˆ™"
            })
```

#### 5.4 æŠ¥å‘Šç”Ÿæˆå™¨ (ReportGenerator)

```python
class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨ - ç”Ÿæˆå¤šç»´åº¦è¯„ä¼°æŠ¥å‘Š"""

    def generate_report(
        self,
        metrics: EvaluationMetrics,
        calibration_report: Dict[str, Any],
        output_format: str = "markdown"
    ) -> str:
        """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
        if output_format == "markdown":
            return self._generate_markdown_report(metrics, calibration_report)
        elif output_format == "json":
            return self._generate_json_report(metrics, calibration_report)
        else:
            raise ValueError(f"Unsupported format: {output_format}")

    def _generate_markdown_report(
        self,
        metrics: EvaluationMetrics,
        calibration_report: Dict[str, Any]
    ) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        report = f"""
# æ„å›¾è¯†åˆ«è¯„ä¼°æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**è¯„ä¼°å‘¨æœŸ**: {metrics.eval_period_start} ~ {metrics.eval_period_end}
**æ ·æœ¬æ•°é‡**: {metrics.sample_count}

---

## ä¸€ã€æ ¸å¿ƒæŒ‡æ ‡æ¦‚è§ˆ

| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |
|------|------|------|
| æ„å›¾å‡†ç¡®ç‡ | {metrics.intent_accuracy:.2%} | {self._status_icon(metrics.intent_accuracy, 0.85)} |
| æ§½ä½ç²¾ç¡®ç‡ | {metrics.slot_precision:.2%} | {self._status_icon(metrics.slot_precision, 0.80)} |
| æ§½ä½å¬å›ç‡ | {metrics.slot_recall:.2%} | {self._status_icon(metrics.slot_recall, 0.80)} |
| æ§½ä½å®Œå…¨åŒ¹é… | {metrics.slot_exact_match:.2%} | {self._status_icon(metrics.slot_exact_match, 0.70)} |
| ä¸šåŠ¡è½¬åŒ–ç‡ | {metrics.business_success_rate:.2%} | {self._status_icon(metrics.business_success_rate, 0.80)} |
| ç½®ä¿¡åº¦æ ¡å‡†è¯¯å·® | {metrics.calibration_error:.2%} | {self._status_icon(1 - metrics.calibration_error, 0.85)} |

---

## äºŒã€å„æ„å›¾è¡¨ç°è¯¦æƒ…

| æ„å›¾ | ç²¾ç¡®ç‡ | å¬å›ç‡ | F1 | çŠ¶æ€ |
|------|--------|--------|-----|------|
"""
        for intent in sorted(metrics.intent_f1.keys()):
            p = metrics.intent_precision.get(intent, 0)
            r = metrics.intent_recall.get(intent, 0)
            f1 = metrics.intent_f1.get(intent, 0)
            report += f"| {intent} | {p:.2%} | {r:.2%} | {f1:.2%} | {self._status_icon(f1, 0.80)} |\n"

        # å‘Šè­¦éƒ¨åˆ†
        if calibration_report.get("alerts"):
            report += "\n---\n\n## ä¸‰ã€å‘Šè­¦ä¿¡æ¯\n\n"
            for alert in calibration_report["alerts"]:
                icon = "ğŸ”´" if alert["level"] == "critical" else "ğŸŸ¡"
                report += f"{icon} **{alert['type']}**: {alert['message']}\n\n"

        # æ ¡å‡†åŠ¨ä½œ
        if calibration_report.get("actions_taken"):
            report += "\n---\n\n## å››ã€è‡ªåŠ¨æ ¡å‡†åŠ¨ä½œ\n\n"
            for action in calibration_report["actions_taken"]:
                report += f"- {action}\n"

        # ä¼˜åŒ–å»ºè®®
        if calibration_report.get("recommendations"):
            report += "\n---\n\n## äº”ã€ä¼˜åŒ–å»ºè®®\n\n"
            for rec in calibration_report["recommendations"]:
                report += f"### æ„å›¾ {rec['intent']}\n"
                report += f"- **é—®é¢˜**: {rec['issue']}\n"
                report += f"- **å»ºè®®**: {rec['suggestion']}\n\n"

        return report

    def _status_icon(self, value: float, threshold: float) -> str:
        """æ ¹æ®é˜ˆå€¼è¿”å›çŠ¶æ€å›¾æ ‡"""
        if value >= threshold:
            return "âœ…"
        elif value >= threshold * 0.9:
            return "âš ï¸"
        else:
            return "âŒ"

    def _generate_json_report(
        self,
        metrics: EvaluationMetrics,
        calibration_report: Dict[str, Any]
    ) -> str:
        """ç”ŸæˆJSONæ ¼å¼æŠ¥å‘Š"""
        report = {
            "generated_at": datetime.now().isoformat(),
            "metrics": {
                "intent_accuracy": metrics.intent_accuracy,
                "slot_precision": metrics.slot_precision,
                "slot_recall": metrics.slot_recall,
                "slot_f1": metrics.slot_f1,
                "business_success_rate": metrics.business_success_rate,
                "calibration_error": metrics.calibration_error,
                "intent_details": {
                    intent: {
                        "precision": metrics.intent_precision.get(intent, 0),
                        "recall": metrics.intent_recall.get(intent, 0),
                        "f1": metrics.intent_f1.get(intent, 0)
                    }
                    for intent in metrics.intent_f1.keys()
                }
            },
            "calibration": calibration_report
        }
        return json.dumps(report, ensure_ascii=False, indent=2)
```

---

### å…­ã€ç³»ç»Ÿé›†æˆ

#### 6.1 Flask API é›†æˆ

```python
# åœ¨ flask_api.py ä¸­é›†æˆ

from calibration import FeedbackCollector, EvaluationEngine, AutoCalibrator, ReportGenerator

# åˆå§‹åŒ–æ ¡å‡†ç³»ç»Ÿ
feedback_collector = FeedbackCollector()
evaluation_engine = EvaluationEngine()
auto_calibrator = AutoCalibrator()
report_generator = ReportGenerator()


@app.route('/rag_query', methods=['POST'])
def rag_query():
    # ... åŸæœ‰é€»è¾‘ ...

    # è®°å½•é¢„æµ‹ï¼ˆæ–°å¢ï¼‰
    record = PredictionRecord(
        query=query,
        predicted_intent=response_dict.get("intent"),
        predicted_slots=response_dict.get("slots", {}),
        confidence_score=calculate_confidence(response)
    )
    record_id = feedback_collector.record_prediction(record)

    # åœ¨å“åº”ä¸­è¿”å›record_idï¼Œä¾›å‰ç«¯å›ä¼ åé¦ˆ
    response["_record_id"] = record_id

    return response


@app.route('/feedback', methods=['POST'])
def collect_feedback():
    """æ¥æ”¶åé¦ˆçš„æ¥å£"""
    data = request.get_json()
    record_id = data.get("record_id")
    feedback_type = data.get("type")

    if feedback_type == "business_result":
        feedback_collector.collect_business_feedback(
            record_id=record_id,
            api_name=data.get("api_name"),
            api_success=data.get("success"),
            error_msg=data.get("error")
        )
    elif feedback_type == "user_behavior":
        feedback_collector.collect_user_behavior(
            record_id=record_id,
            behavior_type=data.get("behavior"),
            detail=data.get("detail")
        )

    return {"status": "ok"}


@app.route('/calibration/report', methods=['GET'])
def get_calibration_report():
    """è·å–æ ¡å‡†æŠ¥å‘Š"""
    records = load_feedback_records()
    metrics = evaluation_engine.evaluate(records)
    calibration_result = auto_calibrator.calibrate(metrics, records)
    report = report_generator.generate_report(
        metrics,
        calibration_result,
        output_format=request.args.get("format", "markdown")
    )
    return {"report": report}
```

#### 6.2 å®šæ—¶ä»»åŠ¡é…ç½®

```python
# calibration_scheduler.py

from apscheduler.schedulers.background import BackgroundScheduler


def setup_calibration_scheduler():
    """è®¾ç½®å®šæ—¶æ ¡å‡†ä»»åŠ¡"""
    scheduler = BackgroundScheduler()

    # æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œè¯„ä¼°å’Œæ ¡å‡†
    scheduler.add_job(
        run_daily_calibration,
        'cron',
        hour=2,
        minute=0
    )

    # æ¯å°æ—¶æ£€æŸ¥å‘Šè­¦
    scheduler.add_job(
        check_alerts,
        'interval',
        hours=1
    )

    scheduler.start()


def run_daily_calibration():
    """æ¯æ—¥æ ¡å‡†ä»»åŠ¡"""
    # 1. åŠ è½½è¿‡å»24å°æ—¶çš„è®°å½•
    records = load_recent_records(hours=24)

    # 2. æ‰§è¡Œè¯„ä¼°
    metrics = evaluation_engine.evaluate(records)

    # 3. æ‰§è¡Œæ ¡å‡†
    calibration_result = auto_calibrator.calibrate(metrics, records)

    # 4. ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š
    report = report_generator.generate_report(metrics, calibration_result)
    save_report(report)

    # 5. å¦‚æœæœ‰ä¸¥é‡å‘Šè­¦ï¼Œå‘é€é€šçŸ¥
    critical_alerts = [a for a in calibration_result["alerts"] if a["level"] == "critical"]
    if critical_alerts:
        send_alert_notification(critical_alerts)

    # 6. å¦‚æœæ ·æœ¬åº“æœ‰æ›´æ–°ï¼Œè§¦å‘Milvusé‡å»º
    if any("æ ·æœ¬åº“å·²æ›´æ–°" in action for action in calibration_result["actions_taken"]):
        trigger_milvus_rebuild()
```

---

### ä¸ƒã€æ–°å¢æ–‡ä»¶ç»“æ„

```
intention_correction/
â”œâ”€â”€ calibration/                    # æ ¡å‡†ç³»ç»Ÿæ¨¡å—ï¼ˆæ–°å¢ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py                   # æ•°æ®æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ feedback_collector.py       # åé¦ˆæ”¶é›†å™¨
â”‚   â”œâ”€â”€ evaluation_engine.py        # è¯„ä¼°å¼•æ“
â”‚   â”œâ”€â”€ auto_calibrator.py          # è‡ªåŠ¨æ ¡å‡†å™¨
â”‚   â”œâ”€â”€ report_generator.py         # æŠ¥å‘Šç”Ÿæˆå™¨
â”‚   â””â”€â”€ scheduler.py                # å®šæ—¶ä»»åŠ¡
â”œâ”€â”€ calibration_data/               # æ ¡å‡†æ•°æ®å­˜å‚¨ï¼ˆæ–°å¢ï¼‰
â”‚   â””â”€â”€ feedback_records/           # åé¦ˆè®°å½•
â”œâ”€â”€ calibration_backups/            # æ ·æœ¬åº“å¤‡ä»½ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ calibration_reports/            # è¯„ä¼°æŠ¥å‘Šï¼ˆæ–°å¢ï¼‰
â””â”€â”€ ... (åŸæœ‰æ–‡ä»¶)
```

---

### å…«ã€ç³»ç»Ÿä¼˜åŠ¿æ€»ç»“

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **æ— éœ€äººå·¥æ ‡æ³¨** | é€šè¿‡ä¸šåŠ¡é—­ç¯å’Œç”¨æˆ·è¡Œä¸ºè‡ªåŠ¨è·å–çœŸå®æ ‡ç­¾ |
| **éä¾µå…¥å¼** | å¼‚æ­¥å¤„ç†ï¼Œä¸å½±å“ä¸»æœåŠ¡æ€§èƒ½ |
| **å¤šç»´åº¦è¯„ä¼°** | æ„å›¾å‡†ç¡®ç‡ + æ§½ä½å‡†ç¡®ç‡ + ä¸šåŠ¡æŒ‡æ ‡ + ç½®ä¿¡åº¦æ ¡å‡† |
| **è‡ªåŠ¨æ ¡å‡†** | è‡ªåŠ¨æ·»åŠ é«˜è´¨é‡æ ·æœ¬ã€ç§»é™¤å™ªå£°æ ·æœ¬ |
| **å¯å›æ»š** | æ¯æ¬¡æ ¡å‡†å‰å¤‡ä»½ï¼Œæ”¯æŒå¿«é€Ÿå›é€€ |
| **å‘Šè­¦æœºåˆ¶** | å‡†ç¡®ç‡ä¸‹é™è‡ªåŠ¨å‘Šè­¦ |
| **æŠ¥å‘Šå¯è§†åŒ–** | æ”¯æŒMarkdown/JSONå¤šç§æ ¼å¼ |

---

### ä¹ã€æŠ¥å‘Šç¤ºä¾‹

```markdown
# æ„å›¾è¯†åˆ«è¯„ä¼°æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: 2025-11-26 02:00:00
**è¯„ä¼°å‘¨æœŸ**: 2025-11-25 02:00:00 ~ 2025-11-26 02:00:00
**æ ·æœ¬æ•°é‡**: 1250

---

## ä¸€ã€æ ¸å¿ƒæŒ‡æ ‡æ¦‚è§ˆ

| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |
|------|------|------|
| æ„å›¾å‡†ç¡®ç‡ | 91.2% | âœ… |
| æ§½ä½ç²¾ç¡®ç‡ | 87.5% | âœ… |
| æ§½ä½å¬å›ç‡ | 82.3% | âœ… |
| æ§½ä½å®Œå…¨åŒ¹é… | 76.8% | âœ… |
| ä¸šåŠ¡è½¬åŒ–ç‡ | 85.2% | âœ… |
| ç½®ä¿¡åº¦æ ¡å‡†è¯¯å·® | 8.3% | âœ… |

---

## äºŒã€å„æ„å›¾è¡¨ç°è¯¦æƒ…

| æ„å›¾ | ç²¾ç¡®ç‡ | å¬å›ç‡ | F1 | çŠ¶æ€ |
|------|--------|--------|-----|------|
| 31 | 94.2% | 92.1% | 93.1% | âœ… |
| 32 | 89.5% | 87.3% | 88.4% | âœ… |
| 33 | 85.2% | 78.6% | 81.8% | âœ… |
| 34 | 91.0% | 88.5% | 89.7% | âœ… |
| 37 | 72.3% | 68.9% | 70.5% | âš ï¸ |
| 40 | 95.8% | 93.2% | 94.5% | âœ… |
| 50 | 68.5% | 71.2% | 69.8% | âš ï¸ |

---

## ä¸‰ã€å‘Šè­¦ä¿¡æ¯

ğŸŸ¡ **intent_performance**: æ„å›¾ 37 çš„F1åˆ†æ•°è¾ƒä½: 70.5%

ğŸŸ¡ **intent_performance**: æ„å›¾ 50 çš„F1åˆ†æ•°è¾ƒä½: 69.8%

---

## å››ã€è‡ªåŠ¨æ ¡å‡†åŠ¨ä½œ

- å·²å¤‡ä»½æ ·æœ¬åº“åˆ° calibration_backups/data_backup_20251126_020000.json
- ç§»é™¤ 3 ä¸ªé—®é¢˜æ ·æœ¬
- æ·»åŠ  12 ä¸ªé«˜è´¨é‡æ ·æœ¬
- æ ·æœ¬åº“å·²æ›´æ–°: 85 â†’ 94

---

## äº”ã€ä¼˜åŒ–å»ºè®®

### æ„å›¾ 37
- **é—®é¢˜**: ç²¾ç¡®ç‡ä½
- **å»ºè®®**: æ„å›¾ 37 å®¹æ˜“è¢«è¯¯åˆ¤ï¼Œå»ºè®®æ·»åŠ æ›´å¤šè¾¹ç•Œæ ·æœ¬æˆ–è°ƒæ•´Promptä¸­çš„åŒºåˆ†è§„åˆ™

### æ„å›¾ 50
- **é—®é¢˜**: å¬å›ç‡ä½
- **å»ºè®®**: æ„å›¾ 50 å®¹æ˜“æ¼åˆ¤ï¼Œå»ºè®®æ·»åŠ æ›´å¤šè¯¥æ„å›¾çš„å¤šæ ·åŒ–è¡¨è¿°æ ·æœ¬
```
